"""
ì˜ì§„ì „ë¬¸ëŒ€ ë„ì„œê´€ OPAC FastAPI - í˜„ì‹¤ì  ìµœì¢… ì†”ë£¨ì…˜
========================================================

ê²°ë¡ : Cheetah OPACì€ ê³µê°œ APIê°€ ì—†ìŒ (ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ 404 ë˜ëŠ” TotalCount:0)
í•´ê²°ì±…: Playwright ìµœì†Œí™” + ê°•ë ¥í•œ ìºì‹œ (Redis/TTL) + ë³‘ë ¬ ì²˜ë¦¬

ì„±ëŠ¥:
- ìºì‹œ íˆíŠ¸: <10ms (99%)
- ìºì‹œ ë¯¸ìŠ¤: 15-30ì´ˆ (Playwright ë¶ˆê°€í”¼)
- ì²« ê²€ìƒ‰ ì´í›„ ì¦‰ì‹œ ì‘ë‹µ

êµì²´ ê°€ì´ë“œ:
1. ê¸°ì¡´ gRPC ì„œë²„ â†’ ì´ FastAPIë¡œ êµì²´
2. Dockerì—ì„œ Redis ì¶”ê°€ (ì„ íƒ)
3. í”„ë¡ íŠ¸ì—”ë“œì—ì„œ /api/library/check í˜¸ì¶œ
"""

from fastapi import FastAPI, HTTPException, Query, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import re
from typing import Optional, Dict, Any
import asyncio
from cachetools import TTLCache
import time
import logging
from playwright.async_api import async_playwright, Browser, BrowserContext

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === ì„¤ì • ===
CACHE_TTL = 1800  # 30ë¶„ (ê¸¸ê²Œ ì„¤ì •)
CACHE_MAXSIZE = 5000  # í¬ê²Œ ì„¤ì •
CONCURRENT_LIMIT = 3  # Playwright ë™ì‹œ ì‹¤í–‰ ì œí•œ (ë‚®ê²Œ)
PLAYWRIGHT_TIMEOUT = 25000  # 25ì´ˆ

# === ì „ì—­ ìƒíƒœ ===
cache = TTLCache(maxsize=CACHE_MAXSIZE, ttl=CACHE_TTL)
cache_lock = asyncio.Lock()
playwright_browser: Optional[Browser] = None
sem = asyncio.Semaphore(CONCURRENT_LIMIT)
stats = {"total": 0, "cache_hits": 0, "playwright_calls": 0}


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ì‹œì‘/ì¢…ë£Œ ì‹œ Playwright ë¸Œë¼ìš°ì € ì¬ì‚¬ìš©"""
    global playwright_browser

    # ì‹œì‘
    pw = await async_playwright().start()
    playwright_browser = await pw.chromium.launch(
        headless=True,
        args=['--no-sandbox', '--disable-setuid-sandbox', '--disable-dev-shm-usage']
    )
    logger.info("âœ… Playwright ë¸Œë¼ìš°ì € ì‹œì‘ (ì¬ì‚¬ìš© ëª¨ë“œ)")

    yield

    # ì¢…ë£Œ
    if playwright_browser:
        await playwright_browser.close()
        logger.info("ğŸ›‘ Playwright ë¸Œë¼ìš°ì € ì¢…ë£Œ")


app = FastAPI(title="YJU Library OPAC - Optimized", version="2.0", lifespan=lifespan)
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])


async def scrape_library_fast(search_term: str) -> Dict[str, Any]:
    """
    Playwright ìµœì í™” ë²„ì „
    - ë¸Œë¼ìš°ì € ì¬ì‚¬ìš© (ë§¤ë²ˆ launch ì•ˆ í•¨)
    - ìµœì†Œ ëŒ€ê¸° ì‹œê°„
    - ë¹ ë¥¸ íŒŒì‹±
    """
    detail_url = f"https://lib.yju.ac.kr/Cheetah/Search/AdvenceSearch#/total/{search_term}"

    try:
        async with sem:  # ë™ì‹œ ì‹¤í–‰ ì œí•œ
            # ìƒˆ ì»¨í…ìŠ¤íŠ¸ë§Œ ìƒì„± (ë¸Œë¼ìš°ì €ëŠ” ì¬ì‚¬ìš©)
            context = await playwright_browser.new_context(
                viewport={'width': 1280, 'height': 720},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            )
            page = await context.new_page()

            try:
                logger.info(f"ğŸ” ê²€ìƒ‰: {search_term}")

                # í˜ì´ì§€ ë¡œë“œ (networkidle ëŒ€ì‹  domcontentloadedë¡œ ë¹ ë¥´ê²Œ)
                await page.goto(detail_url, timeout=PLAYWRIGHT_TIMEOUT, wait_until="domcontentloaded")

                # ìµœì†Œ ëŒ€ê¸° (2ì´ˆë§Œ)
                await page.wait_for_timeout(2000)

                # í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                page_text = await page.inner_text("body")

                # ë¹ ë¥¸ íŒŒì‹±
                found = False
                if re.search(r'ì†Œì¥ìë£Œ\s*(\d+)', page_text):
                    match = re.search(r'ì†Œì¥ìë£Œ\s*(\d+)', page_text)
                    count = int(match.group(1))
                    found = count > 0
                elif any(kw in page_text for kw in ["ëŒ€ì¶œê°€ëŠ¥", "ëŒ€ì¶œì¤‘", "ë‹¨í–‰ë³¸"]):
                    found = True

                if not found:
                    return {"found": False, "available": False, "location": "", "call_number": "", "detail_url": detail_url}

                # ëŒ€ì¶œ ê°€ëŠ¥ ì—¬ë¶€
                available = "ëŒ€ì¶œê°€ëŠ¥" in page_text or "ì´ìš©ê°€ëŠ¥" in page_text

                # ìœ„ì¹˜
                location = "ì†Œì¥"
                for loc in ["ì œ1ìë£Œì‹¤", "ì œ2ìë£Œì‹¤", "ì¤‘ì•™ë„ì„œê´€"]:
                    if loc in page_text:
                        location = loc
                        break

                # ì²­êµ¬ê¸°í˜¸
                call_match = re.search(r'\b(\d{3}(?:\.\d+)?)\b', page_text)
                call_number = call_match.group(1) if call_match else ""

                return {
                    "found": True,
                    "available": available,
                    "location": location,
                    "call_number": call_number,
                    "detail_url": detail_url
                }

            finally:
                await context.close()  # ì»¨í…ìŠ¤íŠ¸ë§Œ ë‹«ê¸°

    except Exception as e:
        logger.error(f"âŒ Playwright ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail=f"ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {str(e)}")


@app.get("/health")
async def health():
    """í—¬ìŠ¤ ì²´í¬"""
    cache_hit_rate = (stats["cache_hits"] / max(stats["total"], 1)) * 100
    return {
        "status": "ok",
        "cache_size": len(cache),
        "cache_hit_rate_percent": round(cache_hit_rate, 2),
        "stats": stats
    }


@app.get("/api/library/check")
async def check_library(
    isbn: Optional[str] = Query(None),
    title: Optional[str] = Query(None)
):
    """
    ì†Œì¥ ì—¬ë¶€ í™•ì¸

    ì„±ëŠ¥:
    - ìºì‹œ íˆíŠ¸: <10ms (ëŒ€ë¶€ë¶„)
    - ìºì‹œ ë¯¸ìŠ¤: 15-30ì´ˆ (Playwright)

    ìºì‹œ ì „ëµ:
    - TTL: 30ë¶„ (ìì£¼ ë³€í•˜ì§€ ì•ŠìŒ)
    - ìµœëŒ€ 5000ê°œ (ì¶©ë¶„í•¨)
    """
    start_time = time.time()
    stats["total"] += 1

    if not isbn and not title:
        raise HTTPException(400, "ISBN ë˜ëŠ” ì œëª© í•„ìš”")

    search_term = re.sub(r'[^0-9]', '', isbn) if isbn else title
    cache_key = f"lib:{search_term}"

    # ìºì‹œ í™•ì¸
    async with cache_lock:
        if cache_key in cache:
            stats["cache_hits"] += 1
            result = cache[cache_key].copy()
            result["cached"] = True
            result["response_time_ms"] = int((time.time() - start_time) * 1000)
            logger.info(f"ğŸ’¾ ìºì‹œ íˆíŠ¸: {search_term} ({result['response_time_ms']}ms)")
            return result

    # Playwright ì‹¤í–‰
    stats["playwright_calls"] += 1
    logger.info(f"ğŸ­ Playwright ì‹¤í–‰: {search_term}")

    result = await scrape_library_fast(search_term)
    result["cached"] = False
    result["response_time_ms"] = int((time.time() - start_time) * 1000)

    # ìºì‹œ ì €ì¥
    async with cache_lock:
        cache[cache_key] = result.copy()

    logger.info(f"âœ… ì™„ë£Œ: {search_term} ({result['response_time_ms']}ms)")

    return result


@app.delete("/api/library/cache")
async def clear_cache():
    """ìºì‹œ ì´ˆê¸°í™”"""
    async with cache_lock:
        count = len(cache)
        cache.clear()
    return {"message": f"ìºì‹œ {count}ê°œ ì‚­ì œ"}


# ====================================================================
# ì„±ëŠ¥ ìµœì í™” ìš”ì•½:
#
# 1. Playwright ë¸Œë¼ìš°ì € ì¬ì‚¬ìš© (launch ë¹„ìš© ì œê±°)
# 2. ë™ì‹œ ì‹¤í–‰ ì œí•œ 3ê°œ (ë¦¬ì†ŒìŠ¤ ë³´í˜¸)
# 3. ìºì‹œ TTL 30ë¶„, ìµœëŒ€ 5000ê°œ
# 4. ìµœì†Œ ëŒ€ê¸° ì‹œê°„ (2ì´ˆë§Œ)
# 5. domcontentloaded (networkidleë³´ë‹¤ ë¹ ë¦„)
#
# ê²°ê³¼:
# - ì²« ê²€ìƒ‰: 15-30ì´ˆ (Playwright ë¶ˆê°€í”¼)
# - ì´í›„ ê²€ìƒ‰: <10ms (ìºì‹œ)
# - ì‹¤ì‚¬ìš© ì‹œ 99% ìºì‹œ íˆíŠ¸ ì˜ˆìƒ
# ====================================================================


if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main_final:app", host="0.0.0.0", port=8090, reload=False, workers=1)


